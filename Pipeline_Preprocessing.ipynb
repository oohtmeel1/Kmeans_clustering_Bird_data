{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.preprocessing import KernelCenterer\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import MiniBatchSparsePCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.decomposition import SparseCoder\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from markdown import markdown\n",
    "import numpy as np\n",
    "import hvplot.pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = ['id', 'huml', 'humw','ulnal', 'ulnaw', 'feml', 'femw', 'tibl', 'tibw', 'tarl', 'tarw', 'type']\n",
    "birds1= pd.read_csv('bird.csv', names=cols,header = 0)\n",
    "birds1=birds1.dropna()\n",
    "birds = birds1.iloc[:,1:12]\n",
    "birds_y = birds['type']\n",
    "birds_x = birds.iloc[:,0:10]\n",
    "label_encoder = LabelEncoder()\n",
    "true_labels = label_encoder.fit_transform(birds_y)\n",
    "label_encoder.classes_\n",
    "n_clusters = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = birds[birds['huml'] < 250]\n",
    "birds = birds[birds['ulnal'] < 220]\n",
    "birds2_x = birds_x[['huml','humw', 'ulnal','ulnaw', 'tarl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(scalerhere):\n",
    "\tpreprocessor = Pipeline([(\"scaler\", scalerhere)])\n",
    "\tclusterer = Pipeline([('kmeans', KMeans(n_clusters = n_clusters, init ='k-means++', n_init=50))])\n",
    "\tpipe = Pipeline([('preprocessor', preprocessor),('clusterer',clusterer)])\n",
    "\tpipe.fit(X_train)\n",
    "\tpreprocessed_data = pipe[\"preprocessor\"].transform(X_train)\n",
    "\tpredicted_labels = pipe[\"clusterer\"][\"kmeans\"].labels_\n",
    "\tscore = silhouette_score(preprocessed_data,predicted_labels)\n",
    "\trand = adjusted_rand_score(true_labels,predicted_labels)\n",
    "\tprint(\"score\",score,\"Adjusted_rand\",rand)\n",
    "\treturn score \n",
    "\treturn rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline(StandardScaler())\n",
    "data_pipeline(MinMaxScaler())\n",
    "data_pipeline(MaxAbsScaler())\n",
    "data_pipeline(RobustScaler())\n",
    "data_pipeline(Normalizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(scalerhere,second):\n",
    "\tpreprocessor = Pipeline([(\"scaler\", scalerhere()),(\"pca\",second())])\n",
    "\tclusterer = Pipeline([('kmeans', KMeans(n_clusters = n_clusters, init ='k-means++', n_init=50))])\n",
    "\tpipe = Pipeline([('preprocessor', preprocessor),('clusterer',clusterer)])\n",
    "\tpipe.fit(birds2_x)\n",
    "\tpreprocessed_data = pipe[\"preprocessor\"].transform(birds2_x)\n",
    "\tpredicted_labels = pipe[\"clusterer\"][\"kmeans\"].labels_\n",
    "\tscore = silhouette_score(preprocessed_data,predicted_labels)\n",
    "\trand = adjusted_rand_score(true_labels,predicted_labels)\n",
    "\tprint(scalerhere,\"score\",score,\"Adjusted_rand\",rand)\n",
    "\treturn score \n",
    "\treturn rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline(StandardScaler,KernelPCA)\n",
    "data_pipeline(MinMaxScaler,KernelPCA)\n",
    "data_pipeline(MaxAbsScaler,KernelPCA)\n",
    "data_pipeline(RobustScaler,KernelPCA)\n",
    "data_pipeline(Normalizer,KernelPCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_pipeline(StandardScaler,PCA)\n",
    "data_pipeline(MinMaxScaler,PCA)\n",
    "data_pipeline(MaxAbsScaler,PCA)\n",
    "data_pipeline(RobustScaler,PCA)\n",
    "data_pipeline(Normalizer,PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(scalerhere, kernel):\n",
    "\tpreprocessor = Pipeline([(\"scaler\", scalerhere()),(\"pca\", KernelPCA(n_components=None, kernel=kernel, gamma=1, fit_inverse_transform=True, alpha=1))])\n",
    "\tclusterer = Pipeline([('kmeans', KMeans(n_clusters = n_clusters, init ='k-means++', n_init=50))])\n",
    "\tpipe = Pipeline([('preprocessor', preprocessor),('clusterer',clusterer)])\n",
    "\tpipe.fit(birds2_x)\n",
    "\tpreprocessed_data = pipe[\"preprocessor\"].transform(birds2_x)\n",
    "\tpredicted_labels = pipe[\"clusterer\"][\"kmeans\"].labels_\n",
    "\tscore = silhouette_score(preprocessed_data,predicted_labels)\n",
    "\trand = adjusted_rand_score(true_labels,predicted_labels)\n",
    "\tprint(\"score\",score,\"Adjusted_rand\",rand)\n",
    "\treturn score \n",
    "\treturn rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline(StandardScaler,'rbf')\n",
    "data_pipeline(MinMaxScaler,'rbf')\n",
    "data_pipeline(MaxAbsScaler,'rbf')\n",
    "data_pipeline(RobustScaler,'rbf')\n",
    "data_pipeline(Normalizer,'rbf')\n",
    "data_pipeline(StandardScaler,'linear')\n",
    "data_pipeline(MinMaxScaler,'linear')\n",
    "data_pipeline(MaxAbsScaler,'linear')\n",
    "data_pipeline(RobustScaler,'linear')\n",
    "data_pipeline(Normalizer,'linear')\n",
    "data_pipeline(StandardScaler,'cosine')\n",
    "data_pipeline(MinMaxScaler,'cosine')\n",
    "data_pipeline(MaxAbsScaler,'cosine')\n",
    "data_pipeline(RobustScaler,'cosine')\n",
    "data_pipeline(Normalizer,'cosine')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
